{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.load_data import load_train, load_test, load_example\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.enable_eager_execution(tf.ConfigProto(log_device_placement=True)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image recognition met een \"normaal\" neuraal netwerk. \n",
    "\n",
    "Neurale netwerken zijn ontzettend sterke wiskundige modellen. Een “normaal” neuraal netwerk heeft echter wel wat limieten. Om een aantal van deze limieten te doorbreken, kan je een convolutional neuraal netwerk gebruiken. \n",
    "\n",
    "We beginnen met het exploreren van de limieten van normale neurale netwerken, dit doen we doormiddel van de MNIST-dataset.\n",
    "\n",
    "MNIST is een dataset van 70.000 handgeschreven cijfers (0..9), opgesplitst in 60.000 training images en 10.000 testing images. We hebben al functies geschreven waarmee je de data kan inladen, zie de cell hieronder.\n",
    "\n",
    "Deze data is steeds opgedeeld in 2 stukken: train en labels.\n",
    "\n",
    "train is een (numpy) array met alle inputafbeeldingen erin.\n",
    "labels is een (numpy) array met voor elke inputafbeelding de werkelijke waarde.\n",
    "\n",
    "Als train[5] een afbeelding van een 4 is, dan geldt dus: labels[5] == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Laad de trainingsdata en labels\n",
    "train_data, train_labels = load_train()\n",
    "# De kleurwaarden in de afbeelding zijn nu 0 tot 255, we zetten deze om naar -0.5 tot 0.5\n",
    "train_data = (train_data / 255) - 0.5\n",
    "\n",
    "\n",
    "plt.imshow(train_data[2])\n",
    "plt.title(f\"{train_labels[2]}\")\n",
    "print(f\"Label: {train_labels[2]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data formatting\n",
    "Voordat we een neuraal netwerk kunnen trainen op de MNIST-data, moet deze verwerkt worden.\n",
    "\n",
    "De input data zijn op het moment grijsafbeeldingen, en dus 2-dimensionaal (x,y).\n",
    "Alleen elke input van dit neuraal netwerk moet 1-dimensionaal zijn. Probeer nu zelf train_data om te zetten naar een\n",
    "correct format. De labels hebben wij zelf al voor je omgezet naar het juiste formaat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels, 10)\n",
    "# There might be a better way to do this?\n",
    "train_data = train_data.reshape(-1,28*31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 868)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handig om te weten: Image recognition geeft in het algemeen ontzettend grote input vectors.\n",
    "MNIST is in grayscale, maar veel plaatjes zijn dat niet. Als je ook nog kleur wil meegeven,\n",
    "zou de input vector nog drie keer zo groot zijn.\n",
    "\n",
    "### Bouwen van een NN\n",
    "\n",
    "De volgende stap is om een neuraal netwerk te bouwen.\n",
    "Maak zelf de eerste Dense layer af, kijk vervolgens ook naar hoeveel hidden layers je toevoegt.\n",
    "Bij image recognition is de activation function ook erg belangrijk.\n",
    "Denk goed na over welke je gebruikt. De laatste layer geven wij alvast aan je.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                27808     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                792       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                250       \n",
      "=================================================================\n",
      "Total params: 29,450\n",
      "Trainable params: 29,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# input_dim moet gelijk zijn aan de lengte van 1 input\n",
    "model.add(Dense(32, input_dim=28*31))\n",
    "model.add(Dense(24))\n",
    "model.add(Dense(24))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieruit kan je al direct het eerste probleem van normale neurale netwerken inzien; er is een gigantische hoeveelheid trainbare parameters. \n",
    "\n",
    "Iedere node moet verbonden zijn aan iedere node. Bij image recognition is de input vector gigantisch, dit houdt dus ook in dat er een gigantische hoeveelheid weights zijn waarmee jouw neuraal netwerk rekening moet houden. \n",
    "\n",
    "Dit maakt het trainen best zwaar en langzaam.\n",
    "\n",
    "Het klaarmaken van een neural network in Keras heeft de volgende stappen:\n",
    "- Aangeven van de layers, dit hebben we net gedaan\n",
    "- Compilen, het model word nu geconfigureerd om hem klaar te maken voor trainen\n",
    "- Fit, het model word nu \"getraind\" op data die je meegeeft. Hieraan geef je zowel data als labels mee\n",
    "- Evaluate; Controller het model om te kijken of het accuraat is. Geef hieraan data en labels mee, maar zorg dat deze data niet ook in je trainingsdata zit\n",
    "- Predict; Geef inputdata mee, waarvan je het label nog niet kent. het NN probeert het label nu te bedenken.\n",
    "Ga nu door met het trainen van dit neuraal netwerk. Ook de `.compile()` hebben wij al aan je geven, ook hier mag je mee spelen.\n",
    "\n",
    "Probeer jouw neuraal netwerk zo accuraat mogelijk te maken. (doe dit door te kijken naar de resultaten van de `.fit()`; `.evaluate()` komt later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:DML:0\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In AI is het aantal epochs het aantal keer dat je over de volledige dataset heen gaat om te trainen.\n",
    "\n",
    "Experimenteer met deze waarde om te kijken wat voor invloed deze heeft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op UnbatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Pack in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorSliceDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DatasetCardinality in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op __inference_initialize_variables_703 in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "Executing op __inference_distributed_function_999 in device /job:localhost/replica:0/task:0/device:DML:0\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.4566 - acc: 0.8623\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.3514 - acc: 0.8970\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3335 - acc: 0.9035\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.3251 - acc: 0.9067\n",
      "Epoch 5/10\n",
      "12512/60000 [=====>........................] - ETA: 3s - loss: 0.3263 - acc: 0.9070"
     ]
    }
   ],
   "source": [
    "model.fit(train_data, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Het evalueren van het neurale netwerk\n",
    "Ook hier moet de data eerst nog omgevormd worden, gebruik hiervoor dezelfde code als bij de training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_labels = load_test()\n",
    "\n",
    "test_data = test_data/255.0 - 0.5\n",
    "\n",
    "\n",
    "test_data =  test_data.reshape(-1,28*31)\n",
    "test_labels = to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 781us/step - loss: 3.2499 - accuracy: 0.4541\n",
      "loss: 3.2499172687530518, accuracy: 0.45410001277923584 van de 1.0\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_data, test_labels)\n",
    "\n",
    "print(f\"loss: {result[0]}, accuracy: {result[1]} van de 1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huh?\n",
    "Hoogstwaarschijnlijk scoort jouw neuraal netwerk nu ontzettend slecht. Om een limiet van neurale netwerken zichtbaar te maken, hebben we een klein beetje valsgespeeld. We hebben wat padding toegevoegd; een aantal pixels aan de linkerkant bij de testing data en een aantal pixels aan de rechterkant bij de training data. Zie de plots hieronder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(example_r, example_l), label = load_example()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].imshow(example_r)\n",
    "axs[0].set_title(\"Padding on right side (Like training)\")\n",
    "\n",
    "axs[1].imshow(example_l)\n",
    "axs[1].set_title(\"Padding on left side (Like testing)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De standaardwaarde voor de padding is 3(!!) pixels, dit heeft een gigantisch effect op de accuratesse.\n",
    "Formatteer nog één keer de data (`examples`), en kijk wat er uit de `.predict()` komt.\n",
    "\n",
    "Er bestaat een kans dat jouw model hier de goede voorspelt, probeer dan bij `load_example()` het argument `index` te veranderen naar een ander getal. Waarschijnlijk zal het dan wel fout voorspellen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = np.array([example_r, example_l]) # FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-58-ce7d59c6e0f2>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    C:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    C:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    C:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected axis -1 of input shape to have value 868 but received input with shape [None, 28, 31]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-ce7d59c6e0f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m--> 453\u001b[1;33m     \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1597\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    C:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    C:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    C:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\ProgramData\\Anaconda3\\envs\\ML-Workshop-CNN\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected axis -1 of input shape to have value 868 but received input with shape [None, 28, 31]\n"
     ]
    }
   ],
   "source": [
    "model.predict_classes(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waarom?\n",
    "\n",
    "De voorspellingen van een gewoon neuraal netwerk zijn ruimtelijk bepaald, het herkent patronen op specifieke plekken. Het verplaatsen van deze patronen met maar een paar pixels kan al genoeg zijn om het onmogelijk te maken voor een gewoon neuraal netwerk om deze te herkennen. \n",
    "\n",
    "Een neuraal netwerk getraind op het herkennen van honden en fietsen, zou heel makkelijk het volgende gedrag kunnen laten zien:\n",
    "\n",
    "\n",
    "\n",
    "![Right!](src/top-left-dog.png)\n",
    "\n",
    "![Wrong!](src/top-left-bike.png)\n",
    "\n",
    "\n",
    "Speel is een beetje rond met de padding, kijk is hoeveel impact 4 pixels heeft, zelfs 1 pixel kan al een grote impact hebben!\n",
    "\n",
    "Wij raden aan om alleen de horizontale padding te veranderen, het format van het padding argument in `load_train`, `load_test`, en `load_example` is dan: `((0, 0), (0, 0), (left sided padding, right sided padding))`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aldewereld, H. & van der Bijl, B. & Bunk, J. (2017, oktober). Applied Artificial Intelligence. Geraadpleegd op 13 maart 2020, van https://canvas.hu.nl/courses/7569/files/694738/download?wrap=1\n",
    "\n",
    "- Chollet, F. (2019, November 6). Getting started with the Keras Sequential model. Geraadpleegd op 13 maart 2020, van keras.io: https://keras.io/getting-started/sequential-model-guide/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
